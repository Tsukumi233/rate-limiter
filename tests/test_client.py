"""
æµ‹è¯•å®¢æˆ·ç«¯ - æ¨¡æ‹Ÿç”Ÿæˆ OpenAI API è¯·æ±‚
"""
import asyncio
import random
import time
import json
from typing import List, Dict, Any
from datetime import datetime
import httpx
from dataclasses import dataclass, field
import argparse
import statistics


@dataclass
class RequestStats:
    """è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯"""
    total_requests: int = 0
    successful_requests: int = 0
    rate_limited_requests: int = 0
    failed_requests: int = 0
    total_input_tokens: int = 0
    total_output_tokens: int = 0
    response_times: List[float] = field(default_factory=list)
    start_time: float = field(default_factory=time.time)
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        elapsed_time = time.time() - self.start_time
        
        return {
            "duration_seconds": elapsed_time,
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "rate_limited_requests": self.rate_limited_requests,
            "failed_requests": self.failed_requests,
            "requests_per_second": self.total_requests / elapsed_time if elapsed_time > 0 else 0,
            "success_rate": self.successful_requests / self.total_requests if self.total_requests > 0 else 0,
            "rate_limit_rate": self.rate_limited_requests / self.total_requests if self.total_requests > 0 else 0,
            "total_input_tokens": self.total_input_tokens,
            "total_output_tokens": self.total_output_tokens,
            "avg_response_time": statistics.mean(self.response_times) if self.response_times else 0,
            "p50_response_time": statistics.median(self.response_times) if self.response_times else 0,
            "p95_response_time": statistics.quantiles(self.response_times, n=20)[18] if len(self.response_times) > 20 else 0,
            "p99_response_time": statistics.quantiles(self.response_times, n=100)[98] if len(self.response_times) > 100 else 0,
        }


class TestClient:
    """OpenAI API æµ‹è¯•å®¢æˆ·ç«¯"""
    
    def __init__(self, server_urls: List[str], api_keys: List[str]):
        self.server_urls = server_urls
        self.api_keys = api_keys
        self.stats = RequestStats()
        
        # é¢„å®šä¹‰çš„æ¶ˆæ¯æ¨¡æ¿
        self.message_templates = [
            "å‘Šè¯‰æˆ‘å…³äºäººå·¥æ™ºèƒ½çš„æœ‰è¶£äº‹å®ã€‚",
            "å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿç»™æˆ‘ä¸€äº›å»ºè®®ã€‚",
            "è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ã€‚",
            "å†™ä¸€ä¸ªå…³äºæœªæ¥ç§‘æŠ€çš„çŸ­æ•…äº‹ã€‚",
            "Python å’Œ JavaScript æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
            "å¦‚ä½•æé«˜å·¥ä½œæ•ˆç‡ï¼Ÿ",
            "è§£é‡Šä¸€ä¸‹åŒºå—é“¾æŠ€æœ¯ã€‚",
            "ç»™æˆ‘æ¨èä¸€äº›å¥½ä¹¦ã€‚",
            "å¦‚ä½•ä¿æŒèº«å¿ƒå¥åº·ï¼Ÿ",
            "ä»‹ç»ä¸€ä¸‹äº‘è®¡ç®—çš„æ¦‚å¿µã€‚"
        ]
        
        self.models = ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"]
    
    def generate_request(self) -> Dict[str, Any]:
        """ç”Ÿæˆéšæœºçš„ OpenAI API è¯·æ±‚"""
        messages = []
        
        # éšæœºç”Ÿæˆ 1-3 æ¡æ¶ˆæ¯
        num_messages = random.randint(1, 3)
        for i in range(num_messages):
            role = "user" if i % 2 == 0 else "assistant"
            content = random.choice(self.message_templates)
            
            # éšæœºå¢åŠ æ¶ˆæ¯é•¿åº¦
            if random.random() < 0.3:
                content += " " + " ".join(["è¿™æ˜¯é¢å¤–çš„å†…å®¹ã€‚"] * random.randint(5, 20))
            
            messages.append({
                "role": role,
                "content": content
            })
        
        # ç¡®ä¿æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯ç”¨æˆ·æ¶ˆæ¯
        if messages[-1]["role"] != "user":
            messages.append({
                "role": "user",
                "content": random.choice(self.message_templates)
            })
        
        request = {
            "model": random.choice(self.models),
            "messages": messages,
            "temperature": random.uniform(0.5, 1.0),
            "max_tokens": random.choice([None, 100, 500, 1000, 2000])
        }
        
        return request
    
    async def send_request(self, client: httpx.AsyncClient, request_data: Dict[str, Any]) -> None:
        """å‘é€å•ä¸ªè¯·æ±‚"""
        # éšæœºé€‰æ‹©æœåŠ¡å™¨å’Œ API Key
        server_url = random.choice(self.server_urls)
        api_key = random.choice(self.api_keys)
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        start_time = time.time()
        
        try:
            response = await client.post(
                f"{server_url}/v1/chat/completions",
                json=request_data,
                headers=headers,
                timeout=30.0
            )
            
            response_time = time.time() - start_time
            self.stats.response_times.append(response_time)
            self.stats.total_requests += 1
            
            if response.status_code == 200:
                self.stats.successful_requests += 1
                data = response.json()
                if "usage" in data:
                    self.stats.total_input_tokens += data["usage"]["prompt_tokens"]
                    self.stats.total_output_tokens += data["usage"]["completion_tokens"]
                
                print(f"âœ… æˆåŠŸ | API Key: {api_key} | å“åº”æ—¶é—´: {response_time:.2f}s")
            
            elif response.status_code == 429:
                self.stats.rate_limited_requests += 1
                print(f"âš ï¸  é™æµ | API Key: {api_key} | {response.headers.get('X-RateLimit-Limit-Requests', 'N/A')} RPM")
            
            else:
                self.stats.failed_requests += 1
                print(f"âŒ å¤±è´¥ | API Key: {api_key} | çŠ¶æ€ç : {response.status_code}")
        
        except Exception as e:
            self.stats.failed_requests += 1
            self.stats.total_requests += 1
            print(f"âŒ é”™è¯¯ | API Key: {api_key} | é”™è¯¯: {str(e)}")
    
    async def run_concurrent_requests(self, num_requests: int, concurrency: int) -> None:
        """å¹¶å‘è¿è¡Œå¤šä¸ªè¯·æ±‚"""
        print(f"\nğŸš€ å¼€å§‹æµ‹è¯•: {num_requests} ä¸ªè¯·æ±‚ï¼Œå¹¶å‘æ•°: {concurrency}")
        print(f"ğŸ“¡ æœåŠ¡å™¨: {self.server_urls}")
        print(f"ğŸ”‘ API Keys: {self.api_keys}\n")
        
        async with httpx.AsyncClient() as client:
            semaphore = asyncio.Semaphore(concurrency)
            
            async def send_with_limit():
                async with semaphore:
                    request_data = self.generate_request()
                    await self.send_request(client, request_data)
            
            # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
            tasks = [send_with_limit() for _ in range(num_requests)]
            
            # å¹¶å‘æ‰§è¡Œ
            await asyncio.gather(*tasks)
    
    def print_stats(self) -> None:
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        summary = self.stats.get_summary()
        
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•ç»Ÿè®¡æŠ¥å‘Š")
        print("="*60)
        
        print(f"\nâ±ï¸  æµ‹è¯•æ—¶é•¿: {summary['duration_seconds']:.2f} ç§’")
        print(f"ğŸ“¨ æ€»è¯·æ±‚æ•°: {summary['total_requests']}")
        print(f"âœ… æˆåŠŸè¯·æ±‚: {summary['successful_requests']} ({summary['success_rate']:.1%})")
        print(f"âš ï¸  é™æµè¯·æ±‚: {summary['rate_limited_requests']} ({summary['rate_limit_rate']:.1%})")
        print(f"âŒ å¤±è´¥è¯·æ±‚: {summary['failed_requests']}")
        
        print(f"\nğŸš„ ååé‡: {summary['requests_per_second']:.2f} è¯·æ±‚/ç§’")
        print(f"ğŸ”¤ æ€»è¾“å…¥ Token: {summary['total_input_tokens']:,}")
        print(f"ğŸ“¤ æ€»è¾“å‡º Token: {summary['total_output_tokens']:,}")
        
        if summary['avg_response_time'] > 0:
            print(f"\nâ±ï¸  å“åº”æ—¶é—´ç»Ÿè®¡:")
            print(f"   â€¢ å¹³å‡: {summary['avg_response_time']:.3f} ç§’")
            print(f"   â€¢ P50: {summary['p50_response_time']:.3f} ç§’")
            print(f"   â€¢ P95: {summary['p95_response_time']:.3f} ç§’")
            print(f"   â€¢ P99: {summary['p99_response_time']:.3f} ç§’")
        
        print("="*60)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="LLM API Rate Limiter æµ‹è¯•å®¢æˆ·ç«¯")
    parser.add_argument("--servers", nargs="+", default=["http://localhost:8000", "http://localhost:8001", "http://localhost:8002"],
                       help="Rate Limiter æœåŠ¡å™¨ URL åˆ—è¡¨")
    parser.add_argument("--api-keys", nargs="+", default=["test-key-1", "test-key-2", "test-key-3"],
                       help="API Key åˆ—è¡¨")
    parser.add_argument("--requests", type=int, default=100, help="æ€»è¯·æ±‚æ•°")
    parser.add_argument("--concurrency", type=int, default=10, help="å¹¶å‘æ•°")
    parser.add_argument("--duration", type=int, help="æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¦‚æœè®¾ç½®åˆ™å¿½ç•¥ --requests")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯
    client = TestClient(args.servers, args.api_keys)
    
    if args.duration:
        # åŸºäºæ—¶é—´çš„æµ‹è¯•
        print(f"â° è¿è¡Œ {args.duration} ç§’çš„è´Ÿè½½æµ‹è¯•...")
        start_time = time.time()
        request_count = 0
        
        while time.time() - start_time < args.duration:
            await client.run_concurrent_requests(args.concurrency, args.concurrency)
            request_count += args.concurrency
        
        print(f"\nğŸ“Š åœ¨ {args.duration} ç§’å†…å‘é€äº† {request_count} ä¸ªè¯·æ±‚")
    else:
        # åŸºäºè¯·æ±‚æ•°çš„æµ‹è¯•
        await client.run_concurrent_requests(args.requests, args.concurrency)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    client.print_stats()


if __name__ == "__main__":
    asyncio.run(main()) 